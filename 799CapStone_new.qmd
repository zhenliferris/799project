---
title: "Analysis for dataset 'Infrared Thermography' "
subtitle: "799 DSAN CapStone Project"
author: "Zhen Li"
date: "2024-06-1"
format:
  pdf:
    documentclass: article
    csl: apa.csl
header-includes: |
  \usepackage{fancyhdr}
  \pagestyle{fancy}
  \fancyhead[L]{Analysis for dataset 'Infrared...' }
bibliography: references.bib
---


# Abstract:

In public gathering areas such as airports, train stations, hospitals, and schools, there is a high likelihood of becoming transmission hubs for infectious diseases. If potential patients can be quickly identified and further screened, it could greatly reduce the risk of spreading infectious diseases. Fever is typically a very common symptom of illness, especially for diseases that can severely threaten public health, such as the recently experienced global outbreak of the COVID19. 

When assessing fever symptoms, the oral temperature is the true value we aim to obtain. Measuring oral temperature for large crowds involves hygiene and time efficiency issues. Without direct contact with the human body, infrared thermography can quickly capture facial temperature. However, the measurement values of infrared thermography can be affected by other factors, thereby reducing the reference value of its readings. The goal of this project is to attempt to establish a good model that accurately predicts the oral temperature of individuals using quickly obtained facial temperature from certain areas and other easily measurable parameters. If the model can provide good predictive performance, it can preliminary and rapidly screen out individuals with fever symptoms for further examination, playing a very positive role in preventing the spread of pandemic diseases.


# Data Understanding:

-  **The data source**

The original data set, FLIR_groups1and2.csv, can be downloaded from: https://doi.org/10.13026/3bhc-9065 [@wang2023facial]
It contains 1020 observations and 4 rounds measurements of 120 variables. Since the purpose of this project is to build a model that can do fast screen, the total of 32 variables, first round of measurements by infrared thermography and environment parameters, are kept for analysis. 

-  **Variables list**


As listed below, Oral temperature is our target value, we want to predict the target value base on the measurement of the feature (input) variables. 


|Variable Name	|Role	|Type|	Description|	 
|:--------------|:------|:----------|:--------------|
|SubjectID|	ID|	Categorical	|	Subject ID|
|T_OR_Max1	|Target|	Continuous|		Oral temperature | 															
|Gender|	Feature|	Categorical	|Male or Female		 |
|Age	|Feature|	Categorical	|	Age ranges in categories |
|Ethnicity|	Feature	|Categorical	|	American Indian or Alaska Native, Asian, Black or African America, Hispanic/Latino, Multiracial, Native Hawaiian or other Pacific Islander, white.		 |
|T_atm|	Feature	|Continuous	|	Ambiant temperature		 |
|Humidity|	Feature	|Continuous	|	Relative humidity	 |
|Distance	|Feature	|Continuous	|	Distance between the subjects and the IRTs 		 |
|T_offset1|Feature|Continuous	|	Temperature difference between the set and measured blackbody temperature|
Max1R13_1	|Feature	|Continuous	|	Max value of a circle with diameter of 13 pixels from the right canthus point to the face centerline	 |
|Max1L13_1|	Feature	|Continuous	|	Max value of a circle with diameter of 13 pixels from the left canthus point to the face centerline		 |
|aveAllR13_1|	Feature|	Continuous	|	Average value of a circle with diameter of 13 pixels from the right canthus point to the face centerline |
|aveAllL13_1| Feature|	Continuous|		Average value of a circle with diameter of 13 pixels from the left canthus point to the face centerline	 |
|T_RC1|	Feature|	Continuous	|	Average temperature of the highest four pixels in a square of 24x24 pixels around the right canthus, with 2/3 toward the face center (dry area, 16x24 pixels) and 1/3 away from the face center (wet area, 8x24 pixels).		 |
|T_RC_Dry1|	Feature|	Continuous|		Average temperature of the highest four pixels in the right canthus dry area, a rectangle of 16x24 pixels.	 |
|T_RC_Wet1|	Feature|	Continuous	|	Average temperature of the highest four pixels in the right canthus wet area, a rectangle of 8x24 pixels.	 |
|T_RC_Max1|	Feature|	Continuous	|	Max value of a square of 24x24 pixels around the right canthus, with 2/3 toward the face center (dry area, 16x24 pixels) and 1/3 away from the face center (wet area, 8x24 pixels).		 |
 |T_LC1|	Feature	|Continuous	|	Average temperature of the highest four pixels in a square of 24x24 pixels around the left canthus, with 2/3 toward the face center (dry area, 16x24 pixels) and 1/3 away from the face center (wet area, 8x24 pixels).				|
|T_LC_Dry1|	Feature	|Continuous	|	Average temperature of the highest four pixels in the left canthus dry area, a rectangle of 16x24 pixels.	 |
|T_LC_Wet1|	Feature|	Continuous	|	Average temperature of the highest four pixels in the left canthus wet area, a rectangle of 16x24 pixels.	 |
|T_LC_Max1|	Feature|	Continuous	|	Max value of a circle with diameter of 13 pixels from the left canthus point to the face centerline	 |
|RCC1|	Feature|	Continuous	|	Average value of a square of 3x3 pixels centered at the right canthus point. |
|LCC1|	Feature	|Continuous	|	Average value of a square of 3x3 pixels centered at the left canthus point.	 |
|canthiMax1|Feature|	Continuous	|	Max value in the extended canthi area	 |
|T_FHCC1|Feature|	Continuous	|	Average temperature within Center point of forehead, a square of 3x3 pixels	 |
|T_FHRC1|Feature|	Continuous	| Average temperature within Right point of the forehead, a square of 3x3 pixels |
|T_FHLC1|Feature|	Continuous	|Average temperature within	Left point of the forehead, a square of 3x3 pixels |
|T_FHBC1|Feature|	Continuous	|Average temperature within	Bottom point of the forehead, a square of 3x3 pixels|
|T_FHTC1|Feature|	Continuous	|	Average temperature within Top point of the forehead, a square of 3x3 pixels	 |
|T_FH_Max1|Feature|	Continuous	|Maximum temperature within the extended
forehead area |
|T_FHC_Max1|Feature|	Continuous	|	Max value in the Center point of forehead, a square of 3x3 pixels	 |
|T_Max1|Feature|	Continuous	|	Maximum temperature within the whole face region |   


-  **Measure Guidance**


The figure 1 shows how all the temperatures are measured from, the picture is from one of the authors who donated the original data set. 


*Figure 1*

[![Mesurement guidance01](C:/799CapStone_Z/facial_oral_temperature_data/_Figure1.png)]    


The figure 2 is a guidance for taking a measurement. Also the environment perimeters will be recorded as input variables.


*Figure 2*

[![Mesurement guidance02](C:/799CapStone_Z/facial_oral_temperature_data/JBO_25_9_097002_f001.png)]

# Data Prepariation:

-  **Load necessary library**

The code listed below is all the R packages used in this analysis. Please note that some  functions defined in different packages are sharing same names, the one in the last loaded package will be a default function. Using '::' to use the specific package.

```{r  warning=FALSE, message=FALSE}
library(tidyverse) #include "dplyr" "ggplot2"
library(Hmisc)
library(psych)
library(scales)
library(caTools) # seed
library(patchwork) # multiplot 
library(car) # vif
library(reshape2) # melt() to convert wide format to long format
library(caret)
library(randomForest)
```


- **Brief look at the selected data**

Firstly, we take a look at the selected variables that we want to analysis. As listed below, there are total of 32 variables and 1020 observations. We notice some variables such as 'T_offset1' has missing values. Some categorical data like 'Age' has defined ranges of "21-25', '26-30', and '21-30', which should be combined into one group to reduce the complication. 

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Read the CSV file
file_path <- "C:/799CapStone_Z/facial_oral_temperature_data/FLIR_groups1and2.csv"
data <- read.csv(file_path, header = FALSE)
data_selected <- data %>% select(3:27, 29, 117:122)

colnames(data_selected) <- data_selected[3,]
data_selected <-data_selected[-(1:3),]
Hmisc::describe(data_selected)
```


- **Dealing the Missing data and combine age group**

By removing the missed values and combining age groups, the cleaned data has 32 variables and 1001 observations. It looks better, but still some of the values looks off. For example, the highest value of 'Distance' is 79, which makes no sense.

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Convert all empty strings to NA
data_selected[data_selected == ""] <- NA

# Remove rows with any NA values
data_cleaned <- data_selected[complete.cases(data_selected), ]

# combine age 21-30 to one group 
data_cleaned$Age[data_cleaned$Age == "21-25" | data_cleaned$Age == "26-30"] <- "21-30"
data_cleaned$Age[data_cleaned$Age == ">60" ] <- "60+"
Hmisc::describe(data_cleaned)
```


- **plot categorical data**

To better understand the data, we take a further look starting with plotting the categorical data.

1. The test subjects are distributed fairly evenly between males and females, with a ratio of 6:4.

2. The data set is predominantly composed of younger individuals under 30, suggesting that the model built on this data may not be suitable for all age groups.

3. Likewise, the distribution of ethnic groups is not balanced, indicating that the model based on this data set may not be appropriate for all ethnicity.

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Categorical data
catvars_plot <- names(data_cleaned)[27:29]
for (catvar in catvars_plot) {
  p <- ggplot(data_cleaned, aes_string(x = catvar, fill=catvar)) +
    geom_bar() +
    labs(title = paste("Bar chart grouped by", catvar), x = catvar, y = "Frequency")+
    coord_flip() +
    theme(legend.text = element_text(size = 8),
          legend.title = element_text(size = 10),
          axis.text.y = element_blank())
  
  print(p)
}

```


- **Covert categorical data to numerical**

To build a model, we convert categorical data to numerical. To reduce complexity, we set the baseline categories as follows: gender is female, age is less than 21, and ethnicity is American Indian. This means that when all other transformed categorical data are set to zero, these default values apply.

```{r echo=FALSE, warning=FALSE, message=FALSE}
mydataframe <- data_cleaned %>% 
  mutate(
    # Encoding categorical variables
    # Gender_Female as base line
    Gender_M = ifelse(Gender == "Male", 1, 0),
    # Age_less20 as base line
    Age_less30 = ifelse(Age == "21-30", 1, 0),
    Age_less40 = ifelse(Age == "31-40", 1, 0),
    Age_less50 = ifelse(Age == "41-50", 1, 0),
    Age_less60 = ifelse(Age == "51-60", 1, 0),
    Age_greater60 = ifelse(Age == "60+", 1, 0),
    # Ethnicity American Indian or Alaskan Native as base line
    Ethnicity_A = ifelse(Ethnicity == "Asian", 1, 0),
    Ethnicity_B = ifelse(Ethnicity == "Black or African-American", 1, 0),
    Ethnicity_H = ifelse(Ethnicity == "Hispanic/Latino", 1, 0),
    Ethnicity_M = ifelse(Ethnicity == "Multiracial", 1, 0),
    Ethnicity_W = ifelse(Ethnicity == "White", 1, 0),
    #variable_SD = scale(variable),
  )

# Removing columns: 'Gender', 'Age', and 'Ethnicity'
mydataframe <- mydataframe[, !(names(mydataframe) %in% c("Gender", "Age", "Ethnicity"))]  

# Ensure all variables are numerical
mydataframe <- mydataframe %>% 
  mutate_if(~ all(!is.na(as.numeric(as.character(.)))), as.numeric)

```


- **self defined Descriptive statistics**

To better describe the numerical data from the original measurement, we define a function that provide basic information regarding data sample size, mean, standard deviation, skew, and kurtosis. 

-  Sample Size (n): Each variable has 1001 observations, indicating a substantial amount of data.
-  Mean: The means of the variables range from around 24 to 36, suggesting the data are centered around these values. The temperature-related variables generally have means around 35, while 'Humidity' has a lower mean (28.76), and 'Distance' has a very low mean (0.731).
-  Standard Deviation (stdev): The standard deviation values indicate the spread of the data. For most temperature-related variables, the standard deviations are around 0.5 to 0.9, indicating relatively low variability. 'Humidity' has a higher variability (stdev of 13.07), which is notable. 'Distance' also shows substantial variability (stdev of 2.48).
-  Skewness: Positive skewness values indicate a right-skewed distribution (e.g., T_offset1, Max1R13_1, etc.). Negative skewness values indicate a left-skewed distribution (e.g., aveAllR13_1, T_FHCC1). Most temperature variables show slight to moderate skewness, indicating some asymmetry in the data distribution.
-  Kurtosis: Kurtosis values close to 3 indicate a normal distribution. Values less than 3 indicate a flatter distribution (platykurtic), while values greater than 3 indicate a more peaked distribution (leptokurtic). The kurtosis values in this dataset range from around 1.64 to 4.88, with most being around 2, suggesting generally platykurtic distributions, except T_FHTC1 which is leptokurtic.
-  Outliers: High skewness and kurtosis in some variables (e.g., T_FHTC1 with kurtosis of 4.88 and skewness of -1.33, Distance with kurtosis of 992.51 and skewness of 31.51) suggest the presence of outliers. 


```{r echo=FALSE, warning=FALSE, message=FALSE}
# Basic descriptive statistics 
des_stats <- function(x, na.omit=FALSE){
  if (na.omit)
    x <- x[!is.na(x)]
  m <- mean(x)
  n <- length(x)
  s <- sd(x)
  skew <- sum((x-m)^3/s^3)/n
  kurt <- sum((x-m)^4/s^4)/n - 3
  return(c(n=n, mean=m, stdev=s,
           skew=skew, kurtosis=kurt))
}
sapply(mydataframe[1:29], des_stats)
```


- **plot numerical data**

```{r echo=FALSE, warning=FALSE, message=FALSE}
i<-1
e<-3
while(i<28){
    plots <- list()
    vars_plot <- names(mydataframe)[i:(i+2)]
    for (var in vars_plot) {
      p <- ggplot(mydataframe, aes_string(x = var)) +
        geom_histogram(aes(y = ..density..), binwidth = 0.1, fill = "blue", alpha = 0.5) +
        geom_density(alpha = .3, fill = "#FF6666") +
        labs(title = paste("Distribution of", var), x = var, y = "Density") +
         theme(
          plot.title = element_text(size = 8),  # Smaller plot title
          axis.title = element_text(size = 6),  # Smaller axis titles
          axis.text = element_text(size = 4)    # Smaller axis text
        )
      
      plots[[var]] <- p
    }
    
    # Combine the plots using patchwork
    combined_plot <- wrap_plots(plots) + plot_layout(ncol = 3)
    
    # Print the combined plot
    print(combined_plot)
    i<-i+3
}
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
plots <- list()
vars_plot <- names(mydataframe)[28:29]
for (var in vars_plot) {
  p <- ggplot(mydataframe, aes_string(x = var)) +
    geom_histogram(aes(y = ..density..), bin=30, fill = "blue", alpha = 0.5) +
    geom_density(alpha = .3, fill = "#FF6666") +
    labs(title = paste("Distribution of", var), x = var, y = "Density")+
  theme(
      plot.title = element_text(size = 8),  # Smaller plot title
      axis.title = element_text(size = 6),  # Smaller axis titles
      axis.text = element_text(size = 4)    # Smaller axis text
    )
  
  plots[[var]] <- p
}

# Combine the plots using patchwork
combined_plot <- wrap_plots(plots) + plot_layout(ncol = 3)

# Print the combined plot
print(combined_plot)
```

- **Dealing the outlier**

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Define a function to detect outliers
detect_outliers <- function(x) {
  Q1 <- quantile(x, 0.25, na.rm = TRUE)
  Q3 <- quantile(x, 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  x < lower_bound | x > upper_bound
}


# Function to remove outliers for specified variables
remove_outliers <- function(df, variables) {
  for (var in variables) {
    if (var %in% names(df)) {
      outliers <- detect_outliers(df[[var]])
      df <- df[!outliers, ]
    }
  }
  return(df)
}
columns_to_clean <- names(mydataframe)[1:29]
mydataframe <- remove_outliers(mydataframe, columns_to_clean)

```


- **Self defined Descriptive statistics w/o outliers **

```{r echo=FALSE, warning=FALSE, message=FALSE}
sapply(mydataframe[1:29], des_stats)
```


- **plot numerical data w/o outliers**

```{r echo=FALSE, warning=FALSE, message=FALSE}
i<-1
e<-3
while(i<28){
    plots <- list()
    vars_plot <- names(mydataframe)[i:(i+2)]
    for (var in vars_plot) {
      p <- ggplot(mydataframe, aes_string(x = var)) +
        geom_histogram(aes(y = ..density..), binwidth = 0.1, fill = "blue", alpha = 0.5) +
        geom_density(alpha = .3, fill = "#FF6666") +
        labs(title = paste("Distribution of", var), x = var, y = "Density") +
         theme(
          plot.title = element_text(size = 8),  # Smaller plot title
          axis.title = element_text(size = 6),  # Smaller axis titles
          axis.text = element_text(size = 4)    # Smaller axis text
        )
      
      plots[[var]] <- p
    }
    
    # Combine the plots using patchwork
    combined_plot <- wrap_plots(plots) + plot_layout(ncol = 3)
    
    # Print the combined plot
    print(combined_plot)
    i<-i+3
}
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
plots <- list()
vars_plot <- names(mydataframe)[28:29]
for (var in vars_plot) {
  p <- ggplot(mydataframe, aes_string(x = var)) +
    geom_histogram(aes(y = ..density..), bin=30, fill = "blue", alpha = 0.5) +
    geom_density(alpha = .3, fill = "#FF6666") +
    labs(title = paste("Distribution of", var), x = var, y = "Density")+
  theme(
      plot.title = element_text(size = 8),  # Smaller plot title
      axis.title = element_text(size = 6),  # Smaller axis titles
      axis.text = element_text(size = 4)    # Smaller axis text
    )
  
  plots[[var]] <- p
}

# Combine the plots using patchwork
combined_plot <- wrap_plots(plots) + plot_layout(ncol = 3)

# Print the combined plot
print(combined_plot)
```
- **correlation of numerical data**


```{r  echo=FALSE, warning=FALSE, message=FALSE, results='hide'}

# Correlation matrix and tests of significance via corr.test() in psych package
corr.test(mydataframe[1:29], use="complete")
```
- **correaltion martix heat map**

```{r echo=FALSE, warning=FALSE, message=FALSE}
corr_result <- corr.test(mydataframe[1:29], use = "complete")

corr_matrix <- corr_result$r
# wider to long form
corr_matrix_melt <- melt(corr_matrix)

ggplot(data = corr_matrix_melt, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() + #heat map tile
  scale_fill_gradient2(low = "blue", high = "red", mid = "white",
                       midpoint = 0, limit = c(-1,1), space = "Lab",
                       name="Correlation") +
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, size = 12, hjust = 1)) +
  coord_fixed() + #Ensures that each tile is square by fixing the aspect ratio.
  labs(title = "Correlation Heatmap", x = "", y = "") +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank())

```

- **Oral temperature VS. denpendent variables**
```{r echo=FALSE, warning=FALSE, message=FALSE}
i<-1
e<-3
while(i<25){
    plots <- list()

    # plot target vs dependent variables
    devars <- names(mydataframe)[i:(i+2)]
    for (var in devars) {
      p <- ggplot(mydataframe, aes_string(x = var, y="T_OR_Max1")) +
        geom_point() +
        geom_smooth(method = "lm", se = TRUE) +
        labs(title = paste("T_OR_Max1 vs.", var), x = var, y = "T_OR_Max1")+
         theme(
          plot.title = element_text(size = 8),  # Smaller plot title
          axis.title = element_text(size = 6),  # Smaller axis titles
          axis.text = element_text(size = 4)    # Smaller axis text
        )
      
      plots[[var]] <- p
    }
     # Combine the plots using patchwork
    combined_plot <- wrap_plots(plots) + plot_layout(ncol = 3)
    
    # Print the combined plot
    print(combined_plot)
    i<-i+3
}

```

```{r echo=FALSE, warning=FALSE, message=FALSE}
plots <- list()
devars <- names(mydataframe)[27:29]
    for (var in devars) {
      p <- ggplot(mydataframe, aes_string(x = var, y="T_OR_Max1")) +
        geom_point() +
        geom_smooth(method = "lm", se = TRUE) +
        labs(title = paste("T_OR_Max1 vs.", var), x = var, y = "T_OR_Max1")+
         theme(
          plot.title = element_text(size = 8),  # Smaller plot title
          axis.title = element_text(size = 6),  # Smaller axis titles
          axis.text = element_text(size = 4)    # Smaller axis text
        )
      
      plots[[var]] <- p
    }
     # Combine the plots using patchwork
    combined_plot <- wrap_plots(plots) + plot_layout(ncol = 3)
    
    # Print the combined plot
    print(combined_plot)
```

- **Standardization of data**
The purpose of standardization 

```{r echo=FALSE, warning=FALSE, message=FALSE}
# standardize variables
mydataframe[, 1:29] <- scale(mydataframe[, 1:29])
```

# Modeling:

- **split data for training and testing by the ration 60:40**
```{r echo=FALSE, warning=FALSE, message=FALSE}
set.seed(42)
split <- sample.split(mydataframe$T_OR_Max1, SplitRatio = 0.6)
train_data <- subset(mydataframe, split == TRUE)
test_data <- subset(mydataframe, split == FALSE)

```
- **Full regression model**
```{r echo=FALSE, warning=FALSE, message=FALSE, results='hide'}
# Full regression model
fit_full <- glm(T_OR_Max1~. ,data=train_data)
```
```{r echo=FALSE, warning=FALSE, message=FALSE}
summary(fit_full)
```
- **Evaluate Full regression model**
```{r echo=FALSE, warning=FALSE, message=FALSE}
vif_values <- vif(fit_full)
print(vif_values)
```

- **Reduced regression model**
```{r echo=FALSE, warning=FALSE, message=FALSE, results='hide'}
# stepwised regression model
fit_reduce <- step(fit_full)
```
```{r echo=FALSE, warning=FALSE, message=FALSE}
summary(fit_reduce)
vif_values <- vif(fit_reduce)
print(vif_values)
```

- **correaltion martix & heat map**
```{r echo=FALSE, warning=FALSE, message=FALSE}
reduced_columns_pca <- mydataframe %>% 
  select(T_offset1, aveAllR13_1, aveAllL13_1, T_RC_Wet1, 
         T_LC_Max1, RCC1, canthi4Max1, T_FHCC1, 
         T_FHLC1, T_FHBC1, T_FH_Max1, T_Max1, 
         T_atm, Humidity, Distance)


corr_result <- corr.test(reduced_columns_pca, use = "complete")

corr_matrix <- corr_result$r
print(round(corr_matrix, 2))
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# wider to long form
corr_matrix_melt <- melt(corr_matrix)

ggplot(data = corr_matrix_melt, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() + #heat map tile
  scale_fill_gradient2(low = "blue", high = "red", mid = "white",
                       midpoint = 0, limit = c(-1,1), space = "Lab",
                       name="Correlation") +
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, size = 12, hjust = 1)) +
  coord_fixed() + #Ensures that each tile is square by fixing the aspect ratio.
  labs(title = "Reduced Regression Correlation Heatmap", x = "", y = "")

```
- **PCA Scree plot**
```{r echo=FALSE, warning=FALSE, message=FALSE, results='hide'}

fa.parallel(reduced_columns_pca, fa = "pc", n.iter = 100,
            show.legend = FALSE, main = "Scree plot with parallel analysis")
abline(h=1)
```
- **PCA Component Eigenvalues**
```{r echo=FALSE, warning=FALSE, message=FALSE}

# Perform PCA using prcomp
pca_result <- prcomp(reduced_columns_pca,
                     center = FALSE, # Data already centered
                     scale. = FALSE) # Data already scaled

# Extract the eigenvalues from the PCA result
eigenvalues <- pca_result$sdev^2

# Print the eigenvalues
print(paste("Component eigenvalues: ", round(eigenvalues, 2)))

```
- **PCA Component contributions**
```{r echo=FALSE, warning=FALSE, message=FALSE}
# Calculate the percentage contributions for each principal component
percentage_contributions <- eigenvalues / sum(eigenvalues) * 100

# Print the percentage contributions
print(paste("Component contributions: ", round(percentage_contributions, 2), "%"))

```
- **Accumulated Component contributions**
```{r echo=FALSE, warning=FALSE, message=FALSE}
# Print accumulated contributions
acc_con <- 0
for (i in seq_along(percentage_contributions)) {
  acc_con <- acc_con + percentage_contributions[i]
  print(paste("Accumulated contribution up to component", i, ": ", round(acc_con, 2), "%"))
}

```
- **Plot for PCA Components**
```{r echo=FALSE, warning=FALSE, message=FALSE}

# Create a data frame for plotting
principal_components <- paste0("PC", 1:length(percentage_contributions))
contributions_df <- data.frame(
  Principal_Component = factor(principal_components, levels = principal_components),
  Percentage_Contribution = percentage_contributions
)

# Plot the percentage contributions
ggplot(contributions_df, aes(x = Principal_Component, y = Percentage_Contribution, fill = Principal_Component)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, size = 12, hjust = 1),
        legend.position = "none")+
  labs(title = "Percentage Contributions of Principal Components",
       x = "Principal Component",
       y = "Percentage Contribution")

```
- **Regression model with first 8 PCA Components**
```{r echo=FALSE, warning=FALSE, message=FALSE}
# Extracting the first 8 principal components
pc_data <- pca_result$x[, 1:8]
# Extracting the first 4 principal components
pc_data_1 <- pca_result$x[, 1:4]
# Extracting the first principal components
pc_data_2 <- pca_result$x[, 1]

reduced_columns_nonepca <- mydataframe %>% 
  select(Ethnicity_W, Ethnicity_M,,T_OR_Max1)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}

# Combine the PCs with the response variable
glm_data <- cbind(pc_data, reduced_columns_nonepca)
set.seed(42)
split <- sample.split(glm_data$T_OR_Max1, SplitRatio = 0.6)
train_data_pca <- subset(glm_data, split == TRUE)
test_data_pca <- subset(glm_data, split == FALSE)

fit_pca <- glm(T_OR_Max1~. ,data=train_data_pca)
summary(fit_pca)
vif_values_pca <- vif(fit_pca)
print(vif_values_pca)

```
- **Regression model with first 4 PCA Components**

```{r echo=FALSE, warning=FALSE, message=FALSE}

# Combine the PCs with the response variable
glm_data_1 <- cbind(pc_data_1, reduced_columns_nonepca)
set.seed(42)
split <- sample.split(glm_data_1$T_OR_Max1, SplitRatio = 0.6)
train_data_pca_1 <- subset(glm_data_1, split == TRUE)
test_data_pca_1 <- subset(glm_data_1, split == FALSE)

fit_pca_1 <- glm(T_OR_Max1~. ,data=train_data_pca_1)
summary(fit_pca_1)
vif_values_pca_1 <- vif(fit_pca_1)
print(vif_values_pca_1)

```
- **Regression model with only first PCA Components**

```{r echo=FALSE, warning=FALSE, message=FALSE}

reduced_columns_nonepca <- mydataframe %>% 
  select(Ethnicity_W, Ethnicity_M,,T_OR_Max1)

# Combine the PCs with the response variable
glm_data_2 <- cbind(pc_data_2, reduced_columns_nonepca)
set.seed(42)
split <- sample.split(glm_data_2$T_OR_Max1, SplitRatio = 0.6)
train_data_pca_2 <- subset(glm_data_2, split == TRUE)
test_data_pca_2 <- subset(glm_data_2, split == FALSE)

fit_pca_2 <- glm(T_OR_Max1~. ,data=train_data_pca_2)
summary(fit_pca_2)
vif_values_pca_2 <- vif(fit_pca_2)
print(vif_values_pca_2)

```
# Findings and Evaluations:


# Deployment and Recommendations:


# References

